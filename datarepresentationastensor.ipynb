{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjIzaUGhyx8en/Bf9ZfjwE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUDHARSAN270/Machine_learning/blob/main/datarepresentationastensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "z3nuY8lp1Zlq"
      },
      "outputs": [],
      "source": [
        "import imageio.v2 as imageio\n",
        "import torch\n",
        "import os\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = imageio.imread(\"/content/Untitled design.jpg\")\n",
        "print(image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m2cexvf7o4b",
        "outputId": "9cb666d6-cc16-4c0d-f248-3ca452a77768"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 1280, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#permute (changing the order)\n",
        "\n",
        "img_t=torch.from_numpy(image)\n",
        "img_t.permute(2,0,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPqcsjXK8NAi",
        "outputId": "9a4df62c-d6ae-4b9d-e9dc-738e0d051d9f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 48,  48,  48,  ..., 132, 133, 133],\n",
              "         [ 48,  48,  48,  ..., 132, 133, 133],\n",
              "         [ 48,  48,  48,  ..., 132, 133, 133],\n",
              "         ...,\n",
              "         [ 30,  30,  30,  ..., 218, 218, 217],\n",
              "         [ 30,  30,  30,  ..., 218, 217, 217],\n",
              "         [ 30,  30,  30,  ..., 218, 217, 216]],\n",
              "\n",
              "        [[ 58,  58,  58,  ..., 137, 138, 138],\n",
              "         [ 58,  58,  58,  ..., 137, 138, 138],\n",
              "         [ 58,  58,  58,  ..., 137, 138, 138],\n",
              "         ...,\n",
              "         [ 39,  39,  39,  ..., 164, 164, 163],\n",
              "         [ 39,  39,  39,  ..., 164, 163, 163],\n",
              "         [ 39,  39,  39,  ..., 164, 163, 162]],\n",
              "\n",
              "        [[  6,   6,   6,  ...,  83,  84,  84],\n",
              "         [  6,   6,   6,  ...,  83,  84,  84],\n",
              "         [  6,   6,   6,  ...,  83,  84,  84],\n",
              "         ...,\n",
              "         [ 10,  10,  10,  ..., 118, 118, 117],\n",
              "         [ 10,  10,  10,  ..., 118, 117, 117],\n",
              "         [ 10,  10,  10,  ..., 118, 117, 116]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# creating batch\n",
        "batch_size = 3\n",
        "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)\n",
        "resize = transforms.Resize((256,256))"
      ],
      "metadata": {
        "id": "zyqQjtbR9toO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/media'\n",
        "filenames = [name for name in os.listdir(data_dir)\n",
        "             if os.path.splitext(name)[-1] == '.png']\n",
        "for i, filename in enumerate(filenames):\n",
        " img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
        " img_t = torch.from_numpy(img_arr)\n",
        " img_t = img_t.permute(2, 0, 1)\n",
        " img_t = img_t[:3]\n",
        " img_t = resize(img_t)\n",
        "\n",
        " batch[i]=img_t"
      ],
      "metadata": {
        "id": "T9iBDdWE_XSU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing\n",
        "\n",
        "batch = batch.float()\n",
        "n_channels = batch.shape[1]\n",
        "for c in range(n_channels):\n",
        " mean = torch.mean(batch[:, c])\n",
        " std = torch.std(batch[:, c])\n",
        " batch[:, c] = (batch[:, c]- mean) / std"
      ],
      "metadata": {
        "id": "uRlqOSvk_5KD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WgE1mYOFHEuk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}